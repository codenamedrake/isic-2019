{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data has 25331 samples.\n",
      "'MEL':\t4522\t(17.85%)\n",
      "'NV':\t12875\t(50.83%)\n",
      "'BCC':\t3323\t(13.12%)\n",
      "'AK':\t867\t(3.42%)\n",
      "'BKL':\t2624\t(10.36%)\n",
      "'DF':\t239\t(0.94%)\n",
      "'VASC':\t253\t(1.00%)\n",
      "'SCC':\t628\t(2.48%)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "df_ground_truth = pd.read_csv('C:\\ISIC_2019\\ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "# Categories not include UNK\n",
    "categories = list(df_ground_truth.columns.values[1:9])\n",
    "# print(categories)\n",
    "\n",
    "int_to_category = dict((i, c) for i, c in enumerate(categories))\n",
    "\n",
    "X = df_ground_truth['image']\n",
    "y = [int_to_category[np.argmax(x)] for x in np.array(df_ground_truth.iloc[:,1:])]\n",
    "count_per_category = Counter(y)\n",
    "total_sample_count = sum(count_per_category.values())\n",
    "print(\"Training data has {} samples.\".format(total_sample_count))\n",
    "\n",
    "for key in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (key, count_per_category[key], count_per_category[key]*100/sample_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 20264 samples.\n",
      "'MEL':\t3618\t(17.85%)\n",
      "'NV':\t10300\t(50.83%)\n",
      "'BCC':\t2658\t(13.12%)\n",
      "'AK':\t694\t(3.42%)\n",
      "'BKL':\t2099\t(10.36%)\n",
      "'DF':\t191\t(0.94%)\n",
      "'VASC':\t202\t(1.00%)\n",
      "'SCC':\t502\t(2.48%)\n",
      "\n",
      "Validation set has 5067 samples.\n",
      "'MEL':\t904\t(17.84%)\n",
      "'NV':\t2575\t(50.82%)\n",
      "'BCC':\t665\t(13.12%)\n",
      "'AK':\t173\t(3.41%)\n",
      "'BKL':\t525\t(10.36%)\n",
      "'DF':\t48\t(0.95%)\n",
      "'VASC':\t51\t(1.01%)\n",
      "'SCC':\t126\t(2.49%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "count_per_category_train = Counter(y_train)\n",
    "sample_count_train = sum(count_per_category_train.values())\n",
    "for key in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (key, count_per_category_train[key], count_per_category_train[key]*100/sample_count_train))\n",
    "    \n",
    "print(\"\\nValidation set has {} samples.\".format(X_val.shape[0]))\n",
    "count_per_category_val = Counter(y_val)\n",
    "sample_count_val = sum(count_per_category_val.values())\n",
    "for key in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (key, count_per_category_val[key], count_per_category_val[key]*100/sample_count_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
