{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# dermoscopic images folder path\n",
    "derm_image_folder = 'C:\\ISIC_2019\\ISIC_2019_Training_Input'\n",
    "df_ground_truth = pd.read_csv('C:\\ISIC_2019\\ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "# Categories not include UNK\n",
    "categories = list(df_ground_truth.columns.values[1:9])\n",
    "known_category_num = len(categories)\n",
    "print(\"Number of known categories: {}\".format(known_category_num))\n",
    "idx_to_category = dict((i, c) for i, c in enumerate(categories))\n",
    "print(idx_to_category, '\\n')\n",
    "\n",
    "df_ground_truth['path'] = df_ground_truth.apply(lambda row : os.path.join(derm_image_folder, row['image']+'.jpg'), axis=1)\n",
    "df_ground_truth['category'] = pd.Series([idx_to_category[np.argmax(x)] for x in np.array(df_ground_truth.iloc[:,1:9])], name='category')\n",
    "count_per_category = Counter(df_ground_truth['category'])\n",
    "total_sample_count = sum(count_per_category.values())\n",
    "print(\"Training data has {} samples.\".format(total_sample_count))\n",
    "\n",
    "for c in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category[c], count_per_category[c]*100/total_sample_count))\n",
    "\n",
    "fig = plt.bar(count_per_category.keys(), count_per_category.values())\n",
    "\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 1\n",
    "df_train, df_val = train_test_split(df_ground_truth, stratify=df_ground_truth['category'], test_size=0.2, random_state=seed)\n",
    "\n",
    "sample_count_train = df_train.shape[0]\n",
    "print(\"Training set has {} samples.\".format(sample_count_train))\n",
    "count_per_category_train = Counter(df_train['category'])\n",
    "for key in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (key, count_per_category_train[key], count_per_category_train[key]*100/sample_count_train))\n",
    "    \n",
    "sample_count_val = df_val.shape[0]\n",
    "print(\"\\nValidation set has {} samples.\".format(sample_count_val))\n",
    "count_per_category_val = Counter(df_val['category'])\n",
    "for key in categories:\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (key, count_per_category_val[key], count_per_category_val[key]*100/sample_count_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples of Each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "category_groups = df_train.groupby('category')\n",
    "\n",
    "# Number of samples for each category\n",
    "num_per_category = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=known_category_num, ncols=num_per_category, figsize=(9, 24))\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "for idx, val in enumerate(categories):\n",
    "    i = 0\n",
    "    for index, row in category_groups.get_group(val).head(num_per_category).iterrows():\n",
    "        ax = axes[idx, i]\n",
    "        ax.imshow(plt.imread(row['path']))\n",
    "        ax.set_xlabel(row['image'])\n",
    "        if ax.is_first_col():\n",
    "            ax.set_ylabel(val, fontsize=20)\n",
    "            ax.yaxis.label.set_color('blue')\n",
    "        i += 1\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import image                  \n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def path_to_tensor(img_path, size=(224, 224)):\n",
    "#     # loads RGB image as PIL.Image.Image type\n",
    "#     img = image.load_img(img_path, target_size=size)\n",
    "#     # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "#     x = image.img_to_array(img)\n",
    "#     # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "#     return np.expand_dims(x, axis=0)\n",
    "\n",
    "# def paths_to_tensor(img_paths, size=(224, 224)):\n",
    "#     list_of_tensors = [path_to_tensor(img_path, size) for img_path in tqdm(img_paths)]\n",
    "#     return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale the images by dividing every pixel in every image by 255.\n",
    "# X_train_tensors = paths_to_tensor(X_train['path'])\n",
    "# X_val_tensors = paths_to_tensor(X_val['path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://stackoverflow.com/a/54620037/2437361\n",
    "import keras.backend as K\n",
    "\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Computes the average per-class recall metric for a multi-class classification problem\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=0)  \n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=0)   \n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    balanced_recall = K.mean(recall)\n",
    "    return balanced_recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vanilla CNN as benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "input_size = (224, 224)\n",
    "batch_size = 40\n",
    "lr_start = 1e-3 # Starting learning rate\n",
    "\n",
    "# datagen_train = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
    "datagen_train = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "datagen_val = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generator_train = datagen_train.flow_from_dataframe(\n",
    "    dataframe=df_train, x_col='path', y_col='category', class_mode='categorical', target_size=input_size, batch_size=batch_size, seed=seed)\n",
    "\n",
    "generator_val = datagen_val.flow_from_dataframe(\n",
    "    dataframe=df_val, x_col='path', y_col='category', class_mode='categorical', target_size=input_size, batch_size=batch_size, seed=seed)\n",
    "\n",
    "# Define vanilla CNN\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(input_size[0], input_size[1], 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Dropout(rate=0.3))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(known_category_num, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=lr_start), loss='categorical_crossentropy', metrics=[balanced_accuracy, 'accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Compute class weights for imbalanced data\n",
    "class_weights = class_weight.compute_class_weight('balanced', np.unique(df_train['category']), df_train['category'])\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "# class_weight_dict = dict(zip(np.unique(df_train['category']), class_weights))\n",
    "print('Class Weights:')\n",
    "print(class_weight_dict)\n",
    "\n",
    "# mapping from class names to class indices\n",
    "print('\\nCategories to Indices:')\n",
    "categories_to_indices = generator_train.class_indices\n",
    "print(categories_to_indices)\n",
    "# print(generator_train.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.makedirs('saved_models')\n",
    "checkpointer = ModelCheckpoint(\n",
    "    filepath='saved_models/vanilla.weights.best.hdf5',\n",
    "    monitor='balanced_accuracy',\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "\n",
    "# Reduce learning rate when the validation loss has stopped improving.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10, min_lr=1e-5, verbose=1)\n",
    "\n",
    "# Stop training when the validation loss has stopped improving.\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=22, verbose=1, restore_best_weights=True)\n",
    "\n",
    "# Callback that streams epoch results to a csv file.\n",
    "if not os.path.exists('logs'):\n",
    "    os.makedirs('logs')\n",
    "csv_logger = CSVLogger('logs/vanilla.training.log')\n",
    "\n",
    "epoch_num = 10\n",
    "\n",
    "history = model.fit_generator(\n",
    "    generator_train,\n",
    "    class_weight=class_weight_dict,\n",
    "    steps_per_epoch=sample_count_train//batch_size,\n",
    "    epochs=epoch_num,\n",
    "    verbose=0,\n",
    "    callbacks=[checkpointer, reduce_lr, early_stop, csv_logger, TQDMNotebookCallback(leave_inner=True, leave_outer=True)],\n",
    "    validation_data=generator_val,\n",
    "    validation_steps=sample_count_val//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
