{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to mount Google Drive for Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "# !ls '/content/drive/My Drive/Colab Notebooks'\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/isic-2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp '/content/drive/My Drive/Colab Notebooks/ISIC_2019_Training_Input.zip' '/home/ISIC_2019_Training_Input.zip'\n",
    "# !cp '/content/drive/My Drive/Colab Notebooks/ISIC_2019_Training_GroundTruth.csv' '/home/ISIC_2019_Training_GroundTruth.csv'\n",
    "# !unzip -qq '/home/ISIC_2019_Training_Input.zip' -d '/home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ref https://docs.fast.ai/performance.html\n",
    "# !pip uninstall -y pillow pil jpeg libtiff libjpeg-turbo\n",
    "# !CFLAGS=\"${CFLAGS} -mavx2\" pip install --upgrade --no-cache-dir --force-reinstall --no-binary :all: --compile pillow-simd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether youâ€™re running Pillow or Pillow-SIMD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the author, if PILLOW_VERSION has a postfix, it is Pillow-SIMD0.\n",
    "# (Assuming that Pillow will never make a .postX release).\n",
    "!python -c \"from PIL import Image; print(Image.PILLOW_VERSION)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whether Pillow or Pillow-SIMD is using libjpeg-turbo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import features, Image\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(Image.PILLOW_VERSION) >= version.parse(\"5.4.0\"):\n",
    "    if features.check_feature('libjpeg_turbo'):\n",
    "        print(\"libjpeg-turbo is on\")\n",
    "    else:\n",
    "        print(\"libjpeg-turbo is not on\")\n",
    "else:\n",
    "    print(\"libjpeg-turbo' status can't be derived - need Pillow(-SIMD)? >= 5.4.0 to tell, current version {}\".format(Image.PILLOW_VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm TensorFlow can see the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print(\"Found GPU at: {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import platform\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "!python3 --version\n",
    "\n",
    "print('\\nTensorFlow Version: ', tf.VERSION)\n",
    "\n",
    "print('\\nNVIDIA:')\n",
    "!nvcc --version\n",
    "# !nvidia-smi\n",
    "\n",
    "print('\\nCPU:')\n",
    "!lscpu\n",
    "\n",
    "print('\\nMemory:')\n",
    "!cat /proc/meminfo\n",
    "\n",
    "print('\\nOS:')\n",
    "print(platform.platform())\n",
    "\n",
    "print('\\nDevices:')\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from data import load_isic_data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# dermoscopic images folder path\n",
    "data_folder = 'C:\\ISIC_2019'\n",
    "# data_folder = '/home'\n",
    "# data_folder = '/home/jupyter'\n",
    "derm_image_folder = os.path.join(data_folder, 'ISIC_2019_Training_Input')\n",
    "ground_truth_file = os.path.join(data_folder, 'ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "df_ground_truth, category_names = load_isic_data(derm_image_folder, ground_truth_file)\n",
    "known_category_num = len(category_names)\n",
    "print(\"Number of known categories: {}\".format(known_category_num))\n",
    "print(category_names, '\\n')\n",
    "\n",
    "# mapping from category to index\n",
    "print('Category to Index:')\n",
    "category_to_index = dict((c, i) for i, c in enumerate(category_names))\n",
    "print(category_to_index, '\\n')\n",
    "\n",
    "count_per_category = Counter(df_ground_truth['category'])\n",
    "total_sample_count = sum(count_per_category.values())\n",
    "print(\"Original training data has {} samples.\".format(total_sample_count))\n",
    "\n",
    "for i, c in enumerate(category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category[i], count_per_category[i]*100/total_sample_count))\n",
    "\n",
    "# fig = plt.bar(count_per_category.keys(), count_per_category.values())\n",
    "fig = plt.bar(category_names, [count_per_category[i] for i in range(len(category_names))])\n",
    "\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Original Training Data into Training  and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import train_validation_split\n",
    "\n",
    "df_train, df_val = train_validation_split(df_ground_truth)\n",
    "\n",
    "sample_count_train = df_train.shape[0]\n",
    "print(\"Training set has {} samples.\".format(sample_count_train))\n",
    "count_per_category_train = Counter(df_train['category'])\n",
    "for i, c in enumerate(category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category_train[i], count_per_category_train[i]*100/sample_count_train))\n",
    "    \n",
    "sample_count_val = df_val.shape[0]\n",
    "print(\"\\nValidation set has {} samples.\".format(sample_count_val))\n",
    "count_per_category_val = Counter(df_val['category'])\n",
    "for i, c in enumerate(category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category_val[i], count_per_category_val[i]*100/sample_count_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights based on the Traning Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import compute_class_weight_dict\n",
    "\n",
    "class_weight_dict = compute_class_weight_dict(df_train)\n",
    "print('Class Weights Dictionary:')\n",
    "print(class_weight_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples of each Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "category_groups = df_train.groupby('category')\n",
    "\n",
    "# Number of samples for each category\n",
    "num_per_category = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=known_category_num, ncols=num_per_category, figsize=(9, 24))\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "for idx, val in enumerate(category_names):\n",
    "    i = 0\n",
    "    for index, row in category_groups.get_group(idx).head(num_per_category).iterrows():\n",
    "        ax = axes[idx, i]\n",
    "        ax.imshow(plt.imread(row['path']))\n",
    "        ax.set_xlabel(row['image'])\n",
    "        if ax.is_first_col():\n",
    "            ax.set_ylabel(val, fontsize=20)\n",
    "            ax.yaxis.label.set_color('blue')\n",
    "        i += 1\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vanilla CNN as Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = (224, 224)\n",
    "batch_size = 40\n",
    "rescale=1./255\n",
    "workers = os.cpu_count()\n",
    "epoch_num = 125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import train_vanilla\n",
    "\n",
    "train_vanilla(df_train, df_val, known_category_num, class_weight_dict, batch_size, epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visuals import *\n",
    "\n",
    "plot_complexity_graph(\"logs/{}.training.csv\".format(classifier.model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model with Best Balanced Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from metrics import balanced_accuracy\n",
    "\n",
    "model = load_model(filepath='saved_models/vanilla_best_balanced_acc.hdf5',\n",
    "                   custom_objects={'balanced_accuracy': balanced_accuracy})\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Balanced Accuracy on all Validation Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from Augmentor import Pipeline\n",
    "from image_iterator import ImageIterator\n",
    "\n",
    "p_val = Pipeline()\n",
    "# Resize the image to the desired input size of the model\n",
    "p_val.resize(probability=1, width=input_size[0], height=input_size[1])\n",
    "        \n",
    "generator = ImageIterator(\n",
    "    image_paths=df_val['path'].tolist(),\n",
    "    labels=np_utils.to_categorical(df_val['category'], num_classes=known_category_num),\n",
    "    augmentation_pipeline=p_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False, #shuffle must be False otherwise will get a wrong balanced accuracy\n",
    "    rescale=rescale,\n",
    "    pregen_augmented_images=False, # Only 1 epoch.\n",
    "    data_format=K.image_data_format()\n",
    ")\n",
    "\n",
    "# print(len(generator))\n",
    "predicted_vector = model.predict_generator(generator, verbose=0, workers=workers)\n",
    "\n",
    "y_true = df_val['category'].values\n",
    "y_pred = np.argmax(predicted_vector, axis=1)\n",
    "\n",
    "print('balanced_accuracy_score: ', balanced_accuracy_score(y_true, y_pred))\n",
    "# print('macro recall_score: ', recall_score(y_true, y_pred, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Dermoscopic Images with the Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils import path_to_tensor\n",
    "\n",
    "def vanilla_classify(img_path, topk=5):\n",
    "    predicted_vector = model.predict(path_to_tensor(img_path))\n",
    "    idx_topk = np.argsort(-predicted_vector)[0, :topk]\n",
    "    probs = np.take(predicted_vector, idx_topk)\n",
    "    names = [category_names[idx] for idx in idx_topk]\n",
    "    \n",
    "    return idx_topk, names, probs\n",
    "\n",
    "topk = known_category_num\n",
    "df_row = df_val.iloc[random.randrange(len(df_val.index))]\n",
    "idx_topk, names, probs = vanilla_classify(df_row['path'], topk=topk)\n",
    "# print(probs)\n",
    "\n",
    "# Set up plot\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(10, 4), ncols=2)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Set up title\n",
    "fig.suptitle(df_row['image'])\n",
    "\n",
    "# Input Image\n",
    "ax1.set_title(category_names[df_row['category']])\n",
    "ax1.imshow(plt.imread(df_row['path']))\n",
    "\n",
    "# Plot probabilities bar chart\n",
    "ax2.set_title(\"Top {0} probabilities\".format(topk))\n",
    "ax2.barh(np.arange(topk), probs)\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(topk))\n",
    "ax2.set_yticklabels(names, size='medium')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlim(0, 1.0)\n",
    "ax2.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models by Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import train_transfer_learning\n",
    "\n",
    "train_transfer_learning(df_train, df_val, known_category_num, class_weight_dict, batch_size, epoch_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity Graph of Transfer Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visuals import *\n",
    "\n",
    "model_names = ['DenseNet201', 'Xception', 'NASNetLarge']\n",
    "for model_name in model_names:\n",
    "    plot_complexity_graph(\"logs/{}.training.csv\".format(model_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
