{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skin Lesion Classifier - Approach 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to mount Google Drive for Colab\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "# !ls '/content/drive/My Drive/Colab Notebooks'\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/My Drive/Colab Notebooks/isic-2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp '/content/drive/My Drive/Colab Notebooks/ISIC_2019_Training_Input.zip' '/home/ISIC_2019_Training_Input.zip'\n",
    "# !cp '/content/drive/My Drive/Colab Notebooks/ISIC_2019_Training_GroundTruth.csv' '/home/ISIC_2019_Training_GroundTruth.csv'\n",
    "# !cp '/content/drive/My Drive/Colab Notebooks/ISIC_2019_Test_Input.zip' '/home/ISIC_2019_Test_Input.zip'\n",
    "# !cp '/content/drive/My Drive/Colab Notebooks/Out_Distribution.zip' '/home/Out_Distribution.zip'\n",
    "# !unzip -qq '/home/ISIC_2019_Training_Input.zip' -d '/home'\n",
    "# !unzip -qq '/home/ISIC_2019_Test_Input.zip' -d '/home'\n",
    "# !unzip -qq '/home/Out_Distribution.zip' -d '/home'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ref https://docs.fast.ai/performance.html\n",
    "# !pip3 uninstall -y pillow pil jpeg libtiff libjpeg-turbo\n",
    "# !CFLAGS=\"${CFLAGS} -mavx2\" pip3 install --upgrade --no-cache-dir --force-reinstall --no-binary :all: --compile pillow-simd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Python Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether youâ€™re running Pillow or Pillow-SIMD?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to the author, if PILLOW_VERSION has a postfix, it is Pillow-SIMD0.\n",
    "# (Assuming that Pillow will never make a .postX release).\n",
    "!python3 -c \"from PIL import Image; print(Image.PILLOW_VERSION)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whether Pillow or Pillow-SIMD is using libjpeg-turbo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import features, Image\n",
    "from packaging import version\n",
    "\n",
    "if version.parse(Image.PILLOW_VERSION) >= version.parse(\"5.4.0\"):\n",
    "    if features.check_feature('libjpeg_turbo'):\n",
    "        print(\"libjpeg-turbo is on\")\n",
    "    else:\n",
    "        print(\"libjpeg-turbo is not on\")\n",
    "else:\n",
    "    print(\"libjpeg-turbo' status can't be derived - need Pillow(-SIMD)? >= 5.4.0 to tell, current version {}\".format(Image.PILLOW_VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confirm TensorFlow can see the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print(\"Found GPU at: {}\".format(device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import platform\n",
    "from tensorflow.python.client import device_lib\n",
    "import keras\n",
    "\n",
    "!python3 --version\n",
    "\n",
    "print('\\nKeras Version: ', keras.__version__)\n",
    "print('\\nTensorFlow Version: ', tf.VERSION)\n",
    "\n",
    "print('\\nNVIDIA:')\n",
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "!nvidia-smi topo -m\n",
    "\n",
    "print('\\nCPU:')\n",
    "!lscpu\n",
    "\n",
    "print('\\nMemory:')\n",
    "!cat /proc/meminfo\n",
    "\n",
    "print('\\nOS:')\n",
    "print(platform.platform())\n",
    "\n",
    "print('\\nDevices:')\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = 'C:\\ISIC_2019'\n",
    "# data_folder = '/home'\n",
    "# data_folder = '/home/jupyter'\n",
    "# data_folder = '/home/ubuntu'\n",
    "\n",
    "model_folder = 'models'\n",
    "history_folder = 'history'\n",
    "pred_result_folder = 'predict_results'\n",
    "out_dist_pred_result_folder = 'out_dist_predict_results'\n",
    "    \n",
    "workers = os.cpu_count()\n",
    "\n",
    "# How to handle SVG fonts\n",
    "plt.rcParams['svg.fonttype'] = 'none'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from data import load_isic_training_data\n",
    "from visuals import autolabel\n",
    "\n",
    "training_image_folder = os.path.join(data_folder, 'ISIC_2019_Training_Input')\n",
    "ground_truth_file = os.path.join(data_folder, 'ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "df_ground_truth, known_category_names, unknown_category_name = load_isic_training_data(training_image_folder, ground_truth_file)\n",
    "known_category_num = len(known_category_names)\n",
    "print(\"Number of known categories: {}\".format(known_category_num))\n",
    "print(known_category_names, '\\n')\n",
    "unknown_category_num = 1\n",
    "print(\"Number of unknown categories: {}\".format(unknown_category_num))\n",
    "print(unknown_category_name, '\\n')\n",
    "all_category_names = known_category_names + [unknown_category_name]\n",
    "all_category_num = known_category_num + unknown_category_num\n",
    "\n",
    "# mapping from category to index\n",
    "print('Category to Index:')\n",
    "category_to_index = dict((c, i) for i, c in enumerate(all_category_names))\n",
    "print(category_to_index, '\\n')\n",
    "\n",
    "count_per_category = Counter(df_ground_truth['category'])\n",
    "total_sample_count = sum(count_per_category.values())\n",
    "print(\"Original training data has {} samples.\".format(total_sample_count))\n",
    "for i, c in enumerate(all_category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category[i], count_per_category[i]*100/total_sample_count))\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "fig.patch.set_facecolor('white')\n",
    "# plt.bar(count_per_category.keys(), count_per_category.values())\n",
    "rects = plt.bar(all_category_names, [count_per_category[i] for i in range(all_category_num)])\n",
    "autolabel(ax, rects)\n",
    "fig.tight_layout()\n",
    "\n",
    "df_ground_truth.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle and Split Original Training Data into Training  and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import train_validation_split\n",
    "from visuals import plot_grouped_2bars\n",
    "\n",
    "df_train, df_val = train_validation_split(df_ground_truth)\n",
    "\n",
    "# Training Set\n",
    "sample_count_train = df_train.shape[0]\n",
    "print(\"Training set has {} samples.\".format(sample_count_train))\n",
    "count_per_category_train = Counter(df_train['category'])\n",
    "for i, c in enumerate(all_category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category_train[i], count_per_category_train[i]*100/sample_count_train))\n",
    "\n",
    "# Validation Set\n",
    "sample_count_val = df_val.shape[0]\n",
    "print(\"\\nValidation set has {} samples.\".format(sample_count_val))\n",
    "count_per_category_val = Counter(df_val['category'])\n",
    "for i, c in enumerate(all_category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_per_category_val[i], count_per_category_val[i]*100/sample_count_val))\n",
    "\n",
    "plot_grouped_2bars(\n",
    "    scalars=[[count_per_category_train[i] for i in range(all_category_num)],\n",
    "             [count_per_category_val[i] for i in range(all_category_num)]],\n",
    "    scalarlabels=['Training', 'Validation'],\n",
    "    xticklabels=all_category_names,\n",
    "    title='Distribution of Training and Validation Sets'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Weights based on the Traning Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import compute_class_weight_dict\n",
    "\n",
    "class_weight_dict, class_weights = compute_class_weight_dict(df_train)\n",
    "print('Class Weights Dictionary (without UNK):')\n",
    "print(class_weight_dict)\n",
    "\n",
    "# Create a bar chart\n",
    "fig, ax = plt.subplots(figsize=(7, 5))\n",
    "fig.patch.set_facecolor('white')\n",
    "ax.set_title('Class Weights')\n",
    "plt.bar(known_category_names, [class_weight_dict[i] for i in range(known_category_num)]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per-channel Mean and Standard Deviation over the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import calculate_mean_std\n",
    "\n",
    "### Uncomment below codes to calculate per-channel mean and standard deviation over the training set\n",
    "# rgb_mean, rgb_std = calculate_mean_std(df_train['path'])\n",
    "# print(\"Mean:{}\\nSTD:{}\".format(rgb_mean, rgb_std))\n",
    "\n",
    "# Output was:\n",
    "# Mean:[0.6236094091893962, 0.5198354883713194, 0.5038435406338101]\n",
    "# STD:[0.2421814437693499, 0.22354427793687906, 0.2314805420919389]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples of each Known Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "category_groups = df_train.groupby('category')\n",
    "\n",
    "# Number of samples for each category\n",
    "num_per_category = 3\n",
    "\n",
    "fig, axes = plt.subplots(nrows=known_category_num, ncols=num_per_category, figsize=(9, 24))\n",
    "plt.setp(plt.gcf().get_axes(), xticks=[], yticks=[])\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "for idx, val in enumerate(known_category_names):\n",
    "    i = 0\n",
    "    for index, row in category_groups.get_group(idx).head(num_per_category).iterrows():\n",
    "        ax = axes[idx, i]\n",
    "        ax.imshow(plt.imread(row['path']))\n",
    "        ax.set_xlabel(row['image'])\n",
    "        if ax.is_first_col():\n",
    "            ax.set_ylabel(val, fontsize=20)\n",
    "            ax.yaxis.label.set_color('blue')\n",
    "        i += 1\n",
    "    \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Vanilla CNN as Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 main.py /home --approach 1 --training --epoch 100 --batchsize 32 --maxqueuesize 10 --model Vanilla"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Complexity Graph of Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from visuals import *\n",
    "\n",
    "fig = plot_complexity_graph(csv_file=os.path.join(history_folder, 'Vanilla.training.csv'),\n",
    "                            title='Complexity Graph of Vanilla CNN')\n",
    "fig.savefig(os.path.join(history_folder, 'Vanilla.training.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify Dermoscopic Images with the Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from utils import path_to_tensor\n",
    "\n",
    "def vanilla_classify(img_path, topk=5):\n",
    "    # TODO: Use Image Augmentation Pipeline instead of path_to_tensor\n",
    "    # Note that path_to_tensor does not rescale images like VanillaClassifier.preprocess_input\n",
    "    predicted_vector = model.predict(path_to_tensor(img_path, size=(224, 224)))\n",
    "    idx_topk = np.argsort(-predicted_vector)[0, :topk]\n",
    "    probs = np.take(predicted_vector, idx_topk)\n",
    "    names = [category_names[idx] for idx in idx_topk]\n",
    "    \n",
    "    return idx_topk, names, probs\n",
    "\n",
    "topk = known_category_num\n",
    "df_row = df_val.iloc[random.randrange(len(df_val.index))]\n",
    "idx_topk, names, probs = vanilla_classify(df_row['path'], topk=topk)\n",
    "# print(probs)\n",
    "\n",
    "# Set up plot\n",
    "fig, (ax1, ax2) = plt.subplots(figsize=(10, 4), ncols=2)\n",
    "fig.patch.set_facecolor('white')\n",
    "\n",
    "# Set up title\n",
    "fig.suptitle(df_row['image'])\n",
    "\n",
    "# Input Image\n",
    "ax1.set_title(category_names[df_row['category']])\n",
    "ax1.imshow(plt.imread(df_row['path']))\n",
    "\n",
    "# Plot probabilities bar chart\n",
    "ax2.set_title(\"Top {0} probabilities\".format(topk))\n",
    "ax2.barh(np.arange(topk), probs)\n",
    "ax2.set_aspect(0.1)\n",
    "ax2.set_yticks(np.arange(topk))\n",
    "ax2.set_yticklabels(names, size='medium')\n",
    "ax2.yaxis.tick_right()\n",
    "ax2.set_xlim(0, 1.0)\n",
    "ax2.invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models by Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!python3 main.py /home --approach 1 --training --epoch 100 --batchsize 32 --maxqueuesize 10 --model DenseNet201 Xception ResNeXt50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complexity Graph of Transfer Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from visuals import *\n",
    "\n",
    "model_names = ['DenseNet201', 'Xception', 'ResNeXt50']\n",
    "feature_extract_epochs = 3\n",
    "\n",
    "for model_name in model_names:\n",
    "    file_path = os.path.join(history_folder, \"{}.training.csv\".format(model_name))\n",
    "    if os.path.exists(file_path):\n",
    "        fig = plot_complexity_graph(csv_file=file_path,\n",
    "                              title=\"Complexity Graph of {}\".format(model_name),\n",
    "                              figsize=(14, 10),\n",
    "                              feature_extract_epochs=feature_extract_epochs)\n",
    "        fig.savefig(os.path.join(history_folder, \"{}.training.svg\".format(model_name)), format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Validation Set by Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !python3 main.py /home --approach 1 --predval --model Vanilla Xception DenseNet201 ResNeXt50\n",
    "!python main.py C:\\ISIC_2019 --approach 1 --predval --model Vanilla Xception DenseNet201 ResNeXt50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Models' Predictions on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ensemble_predictions\n",
    "\n",
    "ensemble_predictions(pred_result_folder, known_category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Prediction Results on Validation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import balanced_accuracy_score, recall_score\n",
    "from visuals import plot_confusion_matrix\n",
    "from keras.utils import np_utils\n",
    "from keras_numpy_backend import categorical_crossentropy\n",
    "\n",
    "model_names = ['Vanilla', 'DenseNet201', 'Xception', 'ResNeXt50', 'Ensemble']\n",
    "postfix = 'best_balanced_acc'\n",
    "print('Model selection criteria: ', postfix)\n",
    "\n",
    "for model_name in model_names:\n",
    "    # Load predicted results\n",
    "    file_path = os.path.join(pred_result_folder, \"{}_{}.csv\".format(model_name, postfix))\n",
    "    # file_path = os.path.join(pred_result_folder, \"{}_best_loss.csv\".format(model_name))\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "\n",
    "    print(\"========== {} ==========\".format(model_name))\n",
    "    df = pd.read_csv(file_path)\n",
    "    y_true = df['category']\n",
    "    y_pred = df['pred_category']\n",
    "\n",
    "    # Compute Balanced Accuracy\n",
    "    print('balanced_accuracy_score: ', balanced_accuracy_score(y_true, y_pred))\n",
    "    print('macro recall_score: ', recall_score(y_true, y_pred, average='macro'))\n",
    "\n",
    "    # Compute categorical_crossentropy\n",
    "    y_true_onehot = np_utils.to_categorical(df['category'], num_classes=known_category_num)\n",
    "    y_pred_onehot = np.array(df.iloc[:,1:9])\n",
    "    print('categorical_crossentropy: ',\n",
    "          np.average(categorical_crossentropy(y_true_onehot, y_pred_onehot)))\n",
    "\n",
    "    # Compute weighted categorical_crossentropy\n",
    "    print('weighted categorical_crossentropy: ',\n",
    "          np.average(categorical_crossentropy(y_true_onehot, y_pred_onehot, class_weights=class_weights)))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    fig = plot_confusion_matrix(y_true, y_pred, known_category_names, normalize=True,\n",
    "                                title=\"Confusion Matrix of {}\".format(model_name),\n",
    "                                figsize=(8, 6))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from visuals import plot_grouped_2bars\n",
    "\n",
    "sample_count_val = y_true.shape[0]\n",
    "print(\"Validation set has {} samples.\\n\".format(sample_count_val))\n",
    "\n",
    "print('========== Ground Truth ==========')\n",
    "count_true = Counter(y_true)\n",
    "for i, c in enumerate(known_category_names):\n",
    "    print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_true[i], count_true[i]*100/sample_count_val))\n",
    "\n",
    "for model_name in model_names:\n",
    "    # Load predicted results\n",
    "    file_path = os.path.join(pred_result_folder, \"{}_{}.csv\".format(model_name, postfix))\n",
    "    if not os.path.exists(file_path):\n",
    "        continue\n",
    "\n",
    "    print(\"\\n========== {} Prediction ==========\".format(model_name))\n",
    "    df = pd.read_csv(file_path)\n",
    "    y_pred = df['pred_category']\n",
    "    \n",
    "    count_pred = Counter(y_pred)\n",
    "    for i, c in enumerate(known_category_names):\n",
    "        print(\"'%s':\\t%d\\t(%.2f%%)\" % (c, count_pred[i], count_pred[i]*100/sample_count_val))\n",
    "\n",
    "    # Plot Prediction Distribution\n",
    "    plot_grouped_2bars(\n",
    "        scalars=[[count_true[i] for i in range(known_category_num)],\n",
    "                 [count_pred[i] for i in range(known_category_num)]],\n",
    "        scalarlabels=['Ground Truth', 'Prediction'],\n",
    "        xticklabels=known_category_names,\n",
    "        title=\"Prediction Distribution of {}\".format(model_name)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Out-of-Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Out-of-Distribution CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import get_dataframe_from_img_folder\n",
    "\n",
    "if not os.path.exists(out_dist_pred_result_folder):\n",
    "    os.makedirs(out_dist_pred_result_folder)\n",
    "    \n",
    "out_dist_image_folder = os.path.join(data_folder, 'Out_Distribution')\n",
    "out_dist_file = os.path.join(out_dist_pred_result_folder, 'Out_Distribution.csv')\n",
    "\n",
    "df_out_dist = get_dataframe_from_img_folder(out_dist_image_folder, has_path_col=False)\n",
    "print(len(df_out_dist), 'out-of-distribution images')\n",
    "df_out_dist.to_csv(out_dist_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Out-of-Distribution Set by Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import load_model\n",
    "from metrics import balanced_accuracy\n",
    "from lesion_classifier import LesionClassifier\n",
    "from vanilla_classifier import VanillaClassifier\n",
    "from base_model_param import get_transfer_model_param_map\n",
    "from keras import backend as K\n",
    "\n",
    "df_out_dist = pd.read_csv(out_dist_file)\n",
    "df_out_dist['path'] = df_out_dist.apply(lambda row : os.path.join(out_dist_image_folder, row['image']+'.jpg'), axis=1)\n",
    "\n",
    "model_names = ['DenseNet201', 'Xception', 'ResNeXt50']\n",
    "postfixes = ['best_balanced_acc', 'best_loss', 'latest']\n",
    "model_param_map = get_transfer_model_param_map()\n",
    "\n",
    "for model_name in model_names:\n",
    "    for postfix in postfixes:\n",
    "        filename = \"{}_{}.hdf5\".format(model_name, postfix)\n",
    "        print('Load: ', filename)\n",
    "        # Load model\n",
    "        model = load_model(filepath=os.path.join(model_folder, filename),\n",
    "                           custom_objects={'balanced_accuracy': balanced_accuracy(known_category_num)})\n",
    "\n",
    "        # Predict Out-of-Distribution Set\n",
    "        df_softmax, df_logit = LesionClassifier.predict_dataframe(\n",
    "            model=model, df=df_out_dist,\n",
    "            category_names=known_category_names,\n",
    "            augmentation_pipeline=LesionClassifier.create_aug_pipeline_val(model_param_map[model_name].input_size),\n",
    "            preprocessing_function=model_param_map[model_name].preprocessing_func,\n",
    "            workers=workers,\n",
    "            softmax_save_file_name=os.path.join(out_dist_pred_result_folder, \"{}_{}.csv\".format(model_name, postfix)),\n",
    "            logit_save_file_name=os.path.join(out_dist_pred_result_folder, \"{}_{}_logit.csv\".format(model_name, postfix)))\n",
    "\n",
    "        del model\n",
    "        K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Models' Predictions on Out-of-Distribution Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ensemble_predictions\n",
    "\n",
    "ensemble_predictions(out_dist_pred_result_folder, known_category_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Baseline and ODIN Softmax Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 main.py /home --approach 1 --odinscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune ODIN Parameters\n",
    "\n",
    "The optimal parameters are chosen to minimize the FPR at TPR 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline Softmax Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from odin import ModelAttr, find_best_delta_at_tpr95, get_tpr_and_fpr, auroc\n",
    "import sys\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_names = ['DenseNet201', 'Xception', 'ResNeXt50']\n",
    "postfixes = ['best_balanced_acc', 'best_loss', 'latest']\n",
    "\n",
    "fpr_min = sys.float_info.max\n",
    "delta_fpr_min = None\n",
    "modelattr_fpr_min = None\n",
    "\n",
    "auroc_max = sys.float_info.min\n",
    "odinparam_auroc_max = None\n",
    "\n",
    "test_size = 0.5\n",
    "random_state = 1\n",
    "\n",
    "for modelattr in (ModelAttr(x, y) for x in model_names for y in postfixes):\n",
    "    print(\"===== {}_{} =====\".format(modelattr.model_name, modelattr.postfix))\n",
    "    in_dist_file=\"softmax_scores/Base/{}_{}_Base_In.txt\".format(modelattr.model_name, modelattr.postfix)\n",
    "    out_dist_file=\"softmax_scores/Base/{}_{}_Base_Out.txt\".format(modelattr.model_name, modelattr.postfix)\n",
    "    scores_in = np.loadtxt(in_dist_file)\n",
    "    scores_out = np.loadtxt(out_dist_file)\n",
    "    scores_in_train, scores_in_test = train_test_split(scores_in, shuffle=True, test_size=test_size, random_state=random_state)\n",
    "    scores_out_train, scores_out_test = train_test_split(scores_out, shuffle=True, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # Compute FPR at TPR 95% using train subset only\n",
    "    fpr, delta = find_best_delta_at_tpr95(scores_in=scores_in_train, scores_out=scores_out_train,\n",
    "                                          delta_start=None, delta_end=None)\n",
    "    print(\"Training FPR:{}, Delta:{}\".format(fpr, delta))\n",
    "    \n",
    "    if fpr < fpr_min:\n",
    "        fpr_min = fpr\n",
    "        delta_fpr_min = delta\n",
    "        modelattr_fpr_min = modelattr\n",
    "        \n",
    "    # Compute FPR on the test subset based on the delta found on training subset\n",
    "    tpr, fpr = get_tpr_and_fpr(scores_in_test, scores_out_test, delta)\n",
    "    print(\"Testing FPR:{}, TPR:{}\".format(fpr, tpr))\n",
    "\n",
    "    # Compute AUROC\n",
    "    auroc_value = auroc(in_dist_file=in_dist_file, out_dist_file=out_dist_file)\n",
    "    print(\"AUROC:{}\\n\".format(auroc_value))\n",
    "    if auroc_value > auroc_max:\n",
    "        auroc_max = auroc_value\n",
    "        odinparam_auroc_max = modelattr\n",
    "\n",
    "print('***** Training Min FPR at TPR 95% *****')\n",
    "print(\"Model:{}_{}, FPR_Min:{}, Delta:{}\\n\"\n",
    "      .format(modelattr_fpr_min.model_name, modelattr_fpr_min.postfix, fpr_min, delta_fpr_min))\n",
    "\n",
    "print('***** Baseline Max AUROC *****')\n",
    "print(\"Model:{}_{}, AUROC:{}\"\n",
    "      .format(modelattr_fpr_min.model_name, modelattr_fpr_min.postfix, auroc_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ODIN Softmax Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from odin import find_best_delta_at_tpr95, auroc\n",
    "from typing import NamedTuple\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "OdinParam = NamedTuple('OdinParam', [('temperature', int), ('magnitude', float)])\n",
    "model_name = 'DenseNet201'\n",
    "postfix = 'best_balanced_acc'\n",
    "temperatures = [1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]\n",
    "magnitudes = np.round(np.arange(0, 0.0041, 0.0002), 4)\n",
    "\n",
    "fpr_min = sys.float_info.max\n",
    "delta_fpr_min = None\n",
    "odinparam_fpr_min = None\n",
    "\n",
    "auroc_max = sys.float_info.min\n",
    "odinparam_auroc_max = None\n",
    "\n",
    "test_size = 0.5\n",
    "random_state = 1\n",
    "\n",
    "for odinparam in (OdinParam(x, y) for x in temperatures for y in magnitudes):\n",
    "    print(\"===== {}_{}, Temperature: {}, Magnitude: {} =====\"\n",
    "          .format(model_name, postfix, odinparam.temperature, odinparam.magnitude))\n",
    "    in_dist_file=\"softmax_scores/{}_{}/{}_{}_ODIN_In.txt\".format(\n",
    "        odinparam.temperature, odinparam.magnitude, model_name, postfix)\n",
    "    out_dist_file=\"softmax_scores/{}_{}/{}_{}_ODIN_Out.txt\".format(\n",
    "        odinparam.temperature, odinparam.magnitude, model_name, postfix)\n",
    "    scores_in = np.loadtxt(in_dist_file)\n",
    "    scores_out = np.loadtxt(out_dist_file)\n",
    "    scores_in_train, scores_in_test = train_test_split(scores_in, shuffle=True, test_size=test_size,\n",
    "                                                       random_state=random_state)\n",
    "    scores_out_train, scores_out_test = train_test_split(scores_out, shuffle=True, test_size=test_size,\n",
    "                                                         random_state=random_state)\n",
    "\n",
    "    # Compute FPR at TPR 95% using training subset only\n",
    "    fpr, delta = find_best_delta_at_tpr95(scores_in=scores_in_train, scores_out=scores_out_train,\n",
    "                                          delta_start=None, delta_end=None)\n",
    "    print(\"Training FPR:{}, Delta:{}\".format(fpr, delta))\n",
    "    if fpr < fpr_min:\n",
    "        fpr_min = fpr\n",
    "        delta_fpr_min = delta\n",
    "        odinparam_fpr_min = odinparam\n",
    "        \n",
    "    # Compute FPR on the test subset based on the delta found on training subset\n",
    "    tpr, fpr = get_tpr_and_fpr(scores_in_test, scores_out_test, delta)\n",
    "    print(\"Testing FPR:{}, TPR:{}\".format(fpr, tpr))\n",
    "\n",
    "    # Compute AUROC\n",
    "    auroc_value = auroc(in_dist_file=in_dist_file, out_dist_file=out_dist_file)\n",
    "    print(\"AUROC:{}\\n\".format(auroc_value))\n",
    "    if auroc_value > auroc_max:\n",
    "        auroc_max = auroc_value\n",
    "        odinparam_auroc_max = odinparam\n",
    "\n",
    "print('***** Training Min FPR at TPR 95% *****')\n",
    "print(\"Model:{}_{}, FPR_Min:{}, Delta:{}, Temperature: {}, Magnitude: {}\\n\"\n",
    "      .format(model_name, postfix, fpr_min, delta_fpr_min, odinparam_fpr_min.temperature, odinparam_fpr_min.magnitude))\n",
    "\n",
    "print('***** ODIN Max AUROC *****')\n",
    "print(\"Model:{}_{}, AUROC:{}, Temperature: {}, Magnitude: {}\"\n",
    "      .format(model_name, postfix, auroc_max, odinparam_auroc_max.temperature, odinparam_auroc_max.magnitude))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curves of Baseline and ODIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, auc\n",
    "\n",
    "# Optimal ODIN Parameters\n",
    "optimal_temperature = 2\n",
    "optimal_magnitude = 0.0002\n",
    "optimal_delta = 0.90385\n",
    "\n",
    "in_dist_files = ['softmax_scores/Base/DenseNet201_best_balanced_acc_Base_In.txt',\n",
    "                 \"softmax_scores/{}_{}/DenseNet201_best_balanced_acc_ODIN_In.txt\".format(optimal_temperature, optimal_magnitude)]\n",
    "out_dist_files = ['softmax_scores/Base/DenseNet201_best_balanced_acc_Base_Out.txt',\n",
    "                  \"softmax_scores/{}_{}/DenseNet201_best_balanced_acc_ODIN_Out.txt\".format(optimal_temperature, optimal_magnitude)]\n",
    "labels = ['Baseline', 'ODIN']\n",
    "colors = ['red', 'blue']\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8))\n",
    "fig.patch.set_facecolor('white')\n",
    "lw = 2\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    scores_in = np.loadtxt(in_dist_files[i])\n",
    "    scores_out = np.loadtxt(out_dist_files[i])\n",
    "    y_true = np.concatenate([np.repeat(1, scores_in.size), np.repeat(0, scores_out.size)])\n",
    "    y_score = np.concatenate([scores_in, scores_out])\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=1)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    label = \"{} (area = {:.2f})\".format(labels[i], roc_auc)\n",
    "    plt.plot(fpr, tpr, color=colors[i], lw=lw, label=label)\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], color='green', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate on Out-of-Distribution Set')\n",
    "plt.ylabel('True Positive Rate on Validation Set')\n",
    "# plt.title(title)\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Set + Out-of-Distribution Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step Function vs. Logistic Function for Out-of-Distribution Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from visuals import plot_confusion_matrix\n",
    "from utils import logistic\n",
    "\n",
    "# In-distribution\n",
    "df_in = pd.read_csv(os.path.join(pred_result_folder, 'Ensemble_best_balanced_acc.csv')).drop(columns=['pred_category'])\n",
    "softmax_scores_in = np.loadtxt(\"softmax_scores/{}_{}/DenseNet201_best_balanced_acc_ODIN_In.txt\"\n",
    "                               .format(optimal_temperature, optimal_magnitude))\n",
    "df_in['softmax_score'] = softmax_scores_in\n",
    "\n",
    "# Out-distribution\n",
    "df_out = pd.read_csv(os.path.join(out_dist_pred_result_folder, 'Ensemble_best_balanced_acc.csv')).drop(columns=['pred_category'])\n",
    "df_out['category'] = category_to_index[unknown_category_name]\n",
    "softmax_scores_out = np.loadtxt(\"softmax_scores/{}_{}/DenseNet201_best_balanced_acc_ODIN_Out.txt\"\n",
    "                                .format(optimal_temperature, optimal_magnitude))\n",
    "df_out['softmax_score'] = softmax_scores_out\n",
    "\n",
    "# Concatenate in- and out-distribution data\n",
    "df = pd.concat([df_in, df_out])\n",
    "\n",
    "# Step function\n",
    "df.insert(loc=9, column=unknown_category_name, value=np.where(df['softmax_score'] > optimal_delta, 0.0, 1.0))\n",
    "df['pred_category'] = np.argmax(np.array(df.iloc[:,1:1+len(all_category_names)]), axis=1)\n",
    "print(\"balanced_accuracy_score:{}\".format(balanced_accuracy_score(df['category'], df['pred_category'])))\n",
    "# Confusion Matrix\n",
    "fig = plot_confusion_matrix(df['category'], df['pred_category'], all_category_names, normalize=True,\n",
    "                            title='Confusion Matrix (Step Function)',\n",
    "                            figsize=(8, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for the best logistic growth rate or steepness of the curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "best_balanced_accuracy_score = sys.float_info.min\n",
    "best_k = None\n",
    "\n",
    "for k in range(1, 1001):\n",
    "    df[unknown_category_name] = 1-logistic(x=df['softmax_score'], x0=optimal_delta, k=k)\n",
    "    # df[unknown_category_name] = [1-logistic(x=x, x0=optimal_delta, k=20) if x > optimal_delta else 1-logistic(x=x, x0=optimal_delta, k=5) for x in df['softmax_score']]\n",
    "    df['pred_category'] = np.argmax(np.array(df.iloc[:,1:1+len(all_category_names)]), axis=1)\n",
    "\n",
    "    # Compute Balanced Accuracy\n",
    "    bac = balanced_accuracy_score(df['category'], df['pred_category'])\n",
    "    if bac > best_balanced_accuracy_score:\n",
    "        best_balanced_accuracy_score = bac\n",
    "        best_k = k\n",
    "\n",
    "print(\"best balanced_accuracy_score:{}, k:{}\".format(best_balanced_accuracy_score, best_k))\n",
    "\n",
    "df[unknown_category_name] = 1-logistic(x=df['softmax_score'], x0=optimal_delta, k=best_k)\n",
    "df['pred_category'] = np.argmax(np.array(df.iloc[:,1:1+len(all_category_names)]), axis=1)\n",
    "\n",
    "# Confusion Matrix\n",
    "fig = plot_confusion_matrix(df['category'], df['pred_category'], all_category_names, normalize=True,\n",
    "                            title='Confusion Matrix (Logistic Function)',\n",
    "                            figsize=(8, 6))\n",
    "    \n",
    "# unknown = df['category'] != 8\n",
    "# df[unknown]\n",
    "# pred_out = df['pred_category'] == 8\n",
    "# df[in_dist & pred_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Test Data by Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 main.py /home --approach 1 --predtest --predresultfolder test_predict_results --model DenseNet201 Xception ResNeXt50"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
